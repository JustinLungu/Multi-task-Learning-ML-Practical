{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-11T13:46:14.136712700Z",
     "start_time": "2023-12-11T13:46:13.860531600Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import preprocessing\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.2\n",
    "    test_ratio = 0.1\n",
    "\n",
    "    train_val, test = train_test_split(df, test_size=test_ratio, random_state=42)\n",
    "    train, val = train_test_split(train_val, test_size=val_ratio/(train_ratio + val_ratio), random_state=42)\n",
    "\n",
    "    return train, val, test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T13:58:25.310209800Z",
     "start_time": "2023-12-11T13:58:25.255819300Z"
    }
   },
   "id": "5b3a473cfec03cba"
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, data_path, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.dataframe.iloc[idx, 0]  # Assuming the image column is 'Image_ID'\n",
    "        img_path = f\"{self.data_path}/{img_name}\"\n",
    "        image = Image.open(img_path)\n",
    "        age = torch.tensor(self.dataframe.iloc[idx,1])\n",
    "        gender = torch.tensor(self.dataframe.iloc[idx,2])\n",
    "        # labels = self.dataframe.iloc[idx, 1:3].values.astype('float32')  # Assuming labels start from column 1\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, [age, gender]\n",
    "\n",
    "# Define transformations for data augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "def preprocess_data(data_path, batch_size=32):\n",
    "    df = pd.read_csv('../data/UTKFace_labels_for_trying.csv', dtype={'Age':'float32', 'Gender':'float32'})\n",
    "    train_data, val_data, test_data = split_data(df)  # Assuming you have a function that splits your data\n",
    "\n",
    "    train_dataset = CustomDataset(dataframe=train_data, data_path=data_path, transform=transform)\n",
    "    val_dataset = CustomDataset(dataframe=val_data, data_path=data_path, transform=transform)\n",
    "    test_dataset = CustomDataset(dataframe=test_data, data_path=data_path)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T13:58:30.721726200Z",
     "start_time": "2023-12-11T13:58:30.680445100Z"
    }
   },
   "id": "b547ad6d82017a66"
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [],
   "source": [
    "data_path = data_path = \"../data/for_trying\"\n",
    "train_loader, val_loader, test_loader = preprocess_data(data_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T13:58:32.020465Z",
     "start_time": "2023-12-11T13:58:31.968470600Z"
    }
   },
   "id": "8371bab70a168c02"
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [],
   "source": [
    "# Iterate through the train_loader to get a batch of data\n",
    "for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "    example_data = data  # This will contain a batch of images\n",
    "    example_targets = targets  # This will contain the corresponding labels/targets\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T13:58:33.014889300Z",
     "start_time": "2023-12-11T13:58:32.927344600Z"
    }
   },
   "id": "aff2bb3e64006bd7"
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.5294,  0.5373,  0.5529,  ...,  0.2157,  0.1843,  0.1608],\n",
      "          [ 0.5216,  0.5216,  0.5373,  ...,  0.2157,  0.1843,  0.1608],\n",
      "          [ 0.5216,  0.5216,  0.5294,  ...,  0.2235,  0.1922,  0.1686],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ...,  0.3176,  0.3255,  0.3176],\n",
      "          [-1.0000, -1.0000, -1.0000,  ...,  0.3098,  0.3176,  0.3333],\n",
      "          [-1.0000, -1.0000, -1.0000,  ...,  0.2863,  0.3020,  0.3255]],\n",
      "\n",
      "         [[ 0.3569,  0.3647,  0.3804,  ..., -0.0118, -0.0431, -0.0667],\n",
      "          [ 0.3490,  0.3490,  0.3725,  ..., -0.0118, -0.0431, -0.0667],\n",
      "          [ 0.3490,  0.3490,  0.3647,  ..., -0.0039, -0.0353, -0.0588],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ...,  0.4902,  0.4902,  0.4824],\n",
      "          [-1.0000, -1.0000, -1.0000,  ...,  0.4824,  0.4902,  0.4980],\n",
      "          [-1.0000, -1.0000, -1.0000,  ...,  0.4667,  0.4745,  0.4902]],\n",
      "\n",
      "         [[-0.0118, -0.0039,  0.0118,  ..., -0.3255, -0.3569, -0.3804],\n",
      "          [-0.0196, -0.0196,  0.0039,  ..., -0.3333, -0.3647, -0.3882],\n",
      "          [-0.0196, -0.0196, -0.0039,  ..., -0.3333, -0.3647, -0.3882],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ...,  0.7020,  0.7020,  0.7020],\n",
      "          [-1.0000, -1.0000, -1.0000,  ...,  0.6863,  0.6941,  0.7098],\n",
      "          [-1.0000, -1.0000, -1.0000,  ...,  0.6549,  0.6706,  0.7020]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2078,  0.0118, -0.2000,  ...,  0.3882,  0.3098,  0.2157],\n",
      "          [ 0.1216, -0.0118, -0.1765,  ...,  0.3804,  0.3020,  0.2000],\n",
      "          [ 0.0667, -0.0118, -0.1373,  ...,  0.3647,  0.2863,  0.1843],\n",
      "          ...,\n",
      "          [ 0.5216,  0.5373,  0.5529,  ...,  0.7725,  0.7804,  0.7882],\n",
      "          [ 0.5137,  0.5373,  0.5529,  ...,  0.7725,  0.7804,  0.7961],\n",
      "          [ 0.5059,  0.5294,  0.5529,  ...,  0.7804,  0.7882,  0.8039]],\n",
      "\n",
      "         [[ 0.1373, -0.0667, -0.2941,  ...,  0.0588,  0.0039, -0.0745],\n",
      "          [ 0.0510, -0.0902, -0.2627,  ...,  0.0510, -0.0039, -0.0902],\n",
      "          [-0.0118, -0.0980, -0.2235,  ...,  0.0431, -0.0196, -0.1059],\n",
      "          ...,\n",
      "          [ 0.1529,  0.1686,  0.1843,  ...,  0.5059,  0.5137,  0.5216],\n",
      "          [ 0.1451,  0.1686,  0.1843,  ...,  0.5059,  0.5137,  0.5294],\n",
      "          [ 0.1373,  0.1608,  0.1843,  ...,  0.5137,  0.5216,  0.5373]],\n",
      "\n",
      "         [[ 0.0667, -0.1451, -0.3647,  ...,  0.0039, -0.0588, -0.1451],\n",
      "          [-0.0196, -0.1686, -0.3412,  ..., -0.0039, -0.0745, -0.1608],\n",
      "          [-0.0824, -0.1686, -0.3020,  ..., -0.0196, -0.0902, -0.1765],\n",
      "          ...,\n",
      "          [ 0.0745,  0.0902,  0.1137,  ...,  0.4118,  0.4196,  0.4275],\n",
      "          [ 0.0667,  0.0902,  0.1137,  ...,  0.4118,  0.4196,  0.4353],\n",
      "          [ 0.0588,  0.0824,  0.1137,  ...,  0.4196,  0.4275,  0.4431]]],\n",
      "\n",
      "\n",
      "        [[[-0.3255,  0.5922,  0.5294,  ...,  0.1922,  0.1843,  0.1686],\n",
      "          [-0.3176,  0.6078,  0.5451,  ...,  0.1843,  0.1765,  0.1843],\n",
      "          [-0.3176,  0.6078,  0.5451,  ...,  0.1922,  0.1922,  0.1922],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-0.3569,  0.5608,  0.4902,  ...,  0.1451,  0.1373,  0.1373],\n",
      "          [-0.3490,  0.5765,  0.5059,  ...,  0.1294,  0.1294,  0.1373],\n",
      "          [-0.3490,  0.5765,  0.5059,  ...,  0.1294,  0.1373,  0.1451],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-0.3882,  0.4745,  0.4039,  ..., -0.0431, -0.0510, -0.0588],\n",
      "          [-0.3804,  0.4902,  0.4196,  ..., -0.0588, -0.0588, -0.0510],\n",
      "          [-0.3804,  0.4902,  0.4196,  ..., -0.0510, -0.0510, -0.0431],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.7255, -0.7098, -0.6941,  ...,  0.3255,  0.3412,  0.3412],\n",
      "          [-0.6784, -0.6706, -0.6627,  ...,  0.3333,  0.3333,  0.3333],\n",
      "          [-0.6706, -0.6549, -0.6471,  ...,  0.3412,  0.3412,  0.3255],\n",
      "          ...,\n",
      "          [ 0.5451,  0.5529,  0.5529,  ...,  0.4039,  0.4039,  0.4039],\n",
      "          [ 0.5216,  0.5451,  0.5529,  ...,  0.4039,  0.4039,  0.4039],\n",
      "          [ 0.4588,  0.4824,  0.4902,  ...,  0.4039,  0.4039,  0.4039]],\n",
      "\n",
      "         [[-0.8118, -0.7961, -0.7804,  ...,  0.2078,  0.2235,  0.2235],\n",
      "          [-0.7882, -0.7725, -0.7647,  ...,  0.2157,  0.2157,  0.2157],\n",
      "          [-0.7804, -0.7647, -0.7490,  ...,  0.2235,  0.2235,  0.2078],\n",
      "          ...,\n",
      "          [ 0.6000,  0.6078,  0.6078,  ...,  0.2863,  0.2863,  0.2863],\n",
      "          [ 0.5765,  0.6000,  0.6078,  ...,  0.2863,  0.2863,  0.2863],\n",
      "          [ 0.5137,  0.5373,  0.5451,  ...,  0.2863,  0.2863,  0.2863]],\n",
      "\n",
      "         [[-0.8431, -0.8275, -0.8118,  ...,  0.1843,  0.2000,  0.2000],\n",
      "          [-0.8118, -0.8039, -0.7882,  ...,  0.1922,  0.1922,  0.1922],\n",
      "          [-0.8118, -0.7961, -0.7804,  ...,  0.2000,  0.2000,  0.1843],\n",
      "          ...,\n",
      "          [ 0.6784,  0.6863,  0.6863,  ...,  0.2627,  0.2627,  0.2627],\n",
      "          [ 0.6549,  0.6784,  0.6863,  ...,  0.2627,  0.2627,  0.2627],\n",
      "          [ 0.5922,  0.6157,  0.6235,  ...,  0.2627,  0.2627,  0.2627]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6078,  0.6000,  0.6000,  ...,  0.4667,  0.4745,  0.4824],\n",
      "          [ 0.6157,  0.6000,  0.6000,  ...,  0.4745,  0.4902,  0.4902],\n",
      "          [ 0.6157,  0.6078,  0.6078,  ...,  0.4824,  0.4902,  0.4824],\n",
      "          ...,\n",
      "          [ 0.5686,  0.5922,  0.6235,  ...,  0.8824,  0.8745,  0.8667],\n",
      "          [ 0.5608,  0.5765,  0.6000,  ...,  0.8824,  0.8667,  0.8588],\n",
      "          [ 0.5765,  0.5686,  0.5843,  ...,  0.8824,  0.8667,  0.8510]],\n",
      "\n",
      "         [[ 0.4039,  0.4196,  0.4510,  ...,  0.2549,  0.2549,  0.2471],\n",
      "          [ 0.4118,  0.4275,  0.4510,  ...,  0.2627,  0.2549,  0.2549],\n",
      "          [ 0.4118,  0.4275,  0.4510,  ...,  0.2627,  0.2627,  0.2549],\n",
      "          ...,\n",
      "          [ 0.5686,  0.5922,  0.6235,  ...,  0.8824,  0.8745,  0.8667],\n",
      "          [ 0.5608,  0.5765,  0.6000,  ...,  0.8824,  0.8667,  0.8588],\n",
      "          [ 0.5765,  0.5686,  0.5843,  ...,  0.8824,  0.8667,  0.8510]],\n",
      "\n",
      "         [[ 0.2706,  0.2863,  0.3176,  ..., -0.1373, -0.1529, -0.1608],\n",
      "          [ 0.2863,  0.2941,  0.3255,  ..., -0.1529, -0.1686, -0.1686],\n",
      "          [ 0.2941,  0.3098,  0.3255,  ..., -0.1765, -0.1922, -0.2078],\n",
      "          ...,\n",
      "          [ 0.5843,  0.6078,  0.6392,  ...,  0.8667,  0.8510,  0.8431],\n",
      "          [ 0.5765,  0.5922,  0.6157,  ...,  0.8667,  0.8510,  0.8431],\n",
      "          [ 0.5922,  0.5843,  0.6000,  ...,  0.8745,  0.8510,  0.8353]]],\n",
      "\n",
      "\n",
      "        [[[-0.2157, -0.1137, -0.0118,  ..., -0.3490, -0.3647, -0.3961],\n",
      "          [-0.2078, -0.1059, -0.0039,  ..., -0.3882, -0.3804, -0.3647],\n",
      "          [-0.2000, -0.1059, -0.0118,  ..., -0.4275, -0.3961, -0.3255],\n",
      "          ...,\n",
      "          [ 0.8431,  0.8510,  0.8510,  ...,  0.6941,  0.6706,  0.6392],\n",
      "          [ 0.8510,  0.8431,  0.8510,  ...,  0.6549,  0.6314,  0.5922],\n",
      "          [ 0.8667,  0.8588,  0.8510,  ...,  0.6078,  0.5843,  0.5451]],\n",
      "\n",
      "         [[-0.3882, -0.3020, -0.2157,  ..., -0.3412, -0.3569, -0.3882],\n",
      "          [-0.3725, -0.2863, -0.2078,  ..., -0.3725, -0.3725, -0.3569],\n",
      "          [-0.3647, -0.2863, -0.2078,  ..., -0.4196, -0.3882, -0.3176],\n",
      "          ...,\n",
      "          [ 0.7490,  0.7412,  0.7333,  ...,  0.6549,  0.6314,  0.6000],\n",
      "          [ 0.7176,  0.7098,  0.6941,  ...,  0.6157,  0.5922,  0.5529],\n",
      "          [ 0.7020,  0.6941,  0.6784,  ...,  0.5686,  0.5451,  0.5059]],\n",
      "\n",
      "         [[-0.6000, -0.5294, -0.4588,  ..., -0.4902, -0.4980, -0.5137],\n",
      "          [-0.5843, -0.5216, -0.4510,  ..., -0.5216, -0.5137, -0.4824],\n",
      "          [-0.5686, -0.5137, -0.4588,  ..., -0.5608, -0.5137, -0.4353],\n",
      "          ...,\n",
      "          [ 0.8118,  0.8118,  0.8118,  ...,  0.6863,  0.6627,  0.6314],\n",
      "          [ 0.7882,  0.7804,  0.7725,  ...,  0.6471,  0.6235,  0.5843],\n",
      "          [ 0.7725,  0.7647,  0.7569,  ...,  0.6000,  0.5765,  0.5373]]]])\r\n"
     ]
    }
   ],
   "source": [
    "tf.print(example_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T13:58:36.843718300Z",
     "start_time": "2023-12-11T13:58:36.692023300Z"
    }
   },
   "id": "651b9b6dc2e120d6"
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([1., 1., 1., 1., 1., 1.]), tensor([0., 0., 0., 0., 0., 0.])]\r\n"
     ]
    }
   ],
   "source": [
    "tf.print(example_targets)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T13:58:38.136301700Z",
     "start_time": "2023-12-11T13:58:38.072243500Z"
    }
   },
   "id": "69187ad155df1267"
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense_shared = nn.Linear(64 * 64 * 64, 128)  # Calculate the input size based on your input_shape\n",
    "\n",
    "        # Output layers\n",
    "        self.classification_output = nn.Linear(128, 1)\n",
    "        self.regression_output = nn.Linear(128, 1)\n",
    "\n",
    "        # Activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.linear = nn.Identity()  # No activation for linear output\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through convolutional layers\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        # Flatten and pass through fully connected layers\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.dense_shared(x))\n",
    "\n",
    "        # Classification branch\n",
    "        classification_out = self.sigmoid(self.classification_output(x)).squeeze()\n",
    "\n",
    "        # Regression branch\n",
    "        regression_out = self.linear(self.regression_output(x)).squeeze()\n",
    "\n",
    "        return regression_out, classification_out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T14:07:55.935152800Z",
     "start_time": "2023-12-11T14:07:55.806626100Z"
    }
   },
   "id": "5410c272a15bee17"
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "outputs": [],
   "source": [
    "class MultiTaskLossWrapper(nn.Module):\n",
    "    def __init__(self, task_num):\n",
    "        super(MultiTaskLossWrapper, self).__init__()\n",
    "        self.task_num = task_num\n",
    "        self.log_vars = nn.Parameter(torch.zeros((task_num)))\n",
    "\n",
    "    def forward(self, age_pred, gen_pred, age_true, gen_true):\n",
    "\n",
    "        mse, binCrossEntropy = nn.MSELoss(), nn.BCELoss()\n",
    "        \n",
    "        loss0 = mse(age_pred, age_true)\n",
    "        loss1 = binCrossEntropy(gen_pred, gen_true)\n",
    "\n",
    "        precision0 = torch.exp(-self.log_vars[0])\n",
    "        loss0 = precision0*loss0 + self.log_vars[0]\n",
    "\n",
    "        precision1 = torch.exp(-self.log_vars[1])\n",
    "        loss1 = precision1*loss1 + self.log_vars[1]\n",
    "\n",
    "        return loss0+loss1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T14:07:57.764424300Z",
     "start_time": "2023-12-11T14:07:57.710617700Z"
    }
   },
   "id": "729ae406f85f4982"
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "outputs": [],
   "source": [
    "model = CustomModel()\n",
    "loss_func = MultiTaskLossWrapper(2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T14:08:02.711011100Z",
     "start_time": "2023-12-11T14:08:00.979078Z"
    }
   },
   "id": "460472292e5c4969"
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: tensor([-0.0620, -0.0452, -0.0320, -0.0347, -0.0545, -0.0559],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "gen: tensor([0.4871, 0.4845, 0.4847, 0.4841, 0.4848, 0.4876],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "Epoch [1/10], Loss: 1.7617\n",
      "age: tensor([40.7081, 39.6753, 42.4140, 28.2802, 38.7958, 40.5531],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "gen: tensor([3.5511e-08, 4.5376e-08, 8.0363e-09, 6.8981e-06, 7.6165e-08, 2.9831e-08],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "Epoch [2/10], Loss: 1420.8022\n",
      "age: tensor([5.0632, 5.1823, 4.9224, 5.0210, 3.9518, 4.6302],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "gen: tensor([0.0006, 0.0005, 0.0008, 0.0005, 0.0037, 0.0004],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "Epoch [3/10], Loss: 14.5755\n",
      "age: tensor([-0.7016, -1.0727, -0.9125, -0.9241, -0.9962, -0.9614],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "gen: tensor([0.0271, 0.0064, 0.0109, 0.0100, 0.0074, 0.0080],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "Epoch [4/10], Loss: 3.7423\n",
      "age: tensor([-0.4064, -0.5240, -0.4750, -0.6029, -0.5082, -0.4776],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "gen: tensor([0.0601, 0.0247, 0.0281, 0.0148, 0.0242, 0.0325],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "Epoch [5/10], Loss: 2.2819\n",
      "age: tensor([-0.1392, -0.2198, -0.1564, -0.1287, -0.1303, -0.1091],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "gen: tensor([0.0572, 0.0352, 0.0519, 0.0643, 0.0569, 0.0954],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "Epoch [6/10], Loss: 1.3796\n",
      "age: tensor([0.0503, 0.0345, 0.0523, 0.0560, 0.0165, 0.0641],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "gen: tensor([0.0986, 0.1264, 0.0904, 0.0961, 0.0638, 0.0886],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "Epoch [7/10], Loss: 1.0100\n",
      "age: tensor([0.1671, 0.1625, 0.1484, 0.1794, 0.1703, 0.1603],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "gen: tensor([0.1262, 0.0999, 0.1691, 0.1252, 0.1353, 0.1412],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "Epoch [8/10], Loss: 0.8407\n",
      "age: tensor([0.1919, 0.2138, 0.2319, 0.2232, 0.2450, 0.2417],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "gen: tensor([0.2066, 0.1881, 0.1688, 0.1785, 0.1695, 0.1407],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "Epoch [9/10], Loss: 0.7947\n",
      "age: tensor([0.2207, 0.2307, 0.2532, 0.2403, 0.2548, 0.2610],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "gen: tensor([0.2456, 0.2312, 0.1928, 0.2271, 0.2153, 0.2162],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "Epoch [10/10], Loss: 0.8230\n"
     ]
    }
   ],
   "source": [
    "# Define your optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # You can adjust the learning rate as needed\n",
    "\n",
    "# Training loop\n",
    "epochs = 10  # Define the number of epochs for training\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()  # Zero the gradients to prevent accumulation\n",
    "        age_pred, gen_pred = model(data)  # Forward pass\n",
    "        age_true = targets[0]\n",
    "        gen_true = targets[1]\n",
    "        print(\"age:\",age_pred)\n",
    "        print(\"gen:\",gen_pred)\n",
    "        # print(targets[0])\n",
    "        # print(age_pred)\n",
    "        # age = targets[:, 0]  # Assuming age is the first element in targets\n",
    "        # gender = targets[:, 1]  # Assuming gender is the second element in targets\n",
    "        # print(age)\n",
    "        loss = loss_func(age_pred, gen_pred, age_true, gen_true)\n",
    "        total_loss += loss.item()\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {avg_loss:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T14:08:18.110477200Z",
     "start_time": "2023-12-11T14:08:03.705097300Z"
    }
   },
   "id": "ba2d97789ee1aa40"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
