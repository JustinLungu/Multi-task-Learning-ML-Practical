{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Get the data and make it suitable for input"
   ],
   "metadata": {
    "id": "LPV7pf95CbhJ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build the multi-task learning"
   ],
   "metadata": {
    "id": "FPV7BTIUCfyA"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0284ZSnNBKPe",
    "outputId": "2cb91579-2b4f-456c-80bd-4840291882b6",
    "ExecuteTime": {
     "end_time": "2023-12-07T15:55:49.401188900Z",
     "start_time": "2023-12-07T15:55:47.103393800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " conv2d_2_input (InputLayer)    [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 126, 126, 64  1792        ['conv2d_2_input[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 124, 124, 64  36928       ['conv2d_2[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 62, 62, 64)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 246016)       0           ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 128)          31490176    ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 64)           8256        ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 64)           8256        ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " binary_classification_output (  (None, 1)           65          ['dense_4[0][0]']                \n",
      " Dense)                                                                                           \n",
      "                                                                                                  \n",
      " regression_output (Dense)      (None, 1)            65          ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,545,538\n",
      "Trainable params: 31,545,538\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define the shared base model\n",
    "def build_shared_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    return model\n",
    "\n",
    "# Define the binary classification head\n",
    "def build_binary_classification_head(base_model_output):\n",
    "    x = layers.Dense(64, activation='relu')(base_model_output)\n",
    "    binary_classification_output = layers.Dense(1, activation='sigmoid', name='binary_classification_output')(x)\n",
    "    return binary_classification_output\n",
    "\n",
    "# Define the regression head\n",
    "def build_regression_head(base_model_output):\n",
    "    x = layers.Dense(64, activation='relu')(base_model_output)\n",
    "    regression_output = layers.Dense(1, name='regression_output')(x)\n",
    "    return regression_output\n",
    "\n",
    "# Input shape for the image\n",
    "input_shape = (128, 128, 3)\n",
    "\n",
    "# Number of classes for binary classification\n",
    "num_classes_binary = 1\n",
    "\n",
    "# Shared base model\n",
    "base_model = build_shared_model(input_shape)\n",
    "\n",
    "# Binary classification head\n",
    "binary_classification_output = build_binary_classification_head(base_model.output)\n",
    "\n",
    "# Regression head\n",
    "regression_output = build_regression_head(base_model.output)\n",
    "\n",
    "# Create the multi-task model\n",
    "model = models.Model(inputs=base_model.input, outputs=[binary_classification_output, regression_output])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss={'binary_classification_output': 'binary_crossentropy', 'regression_output': 'mse'},\n",
    "              metrics={'binary_classification_output': 'accuracy', 'regression_output': 'mse'})\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the model"
   ],
   "metadata": {
    "id": "MccBOaBvCjZB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Assuming you have X_train (input images), y_class (classification labels), and y_reg (regression labels)\n",
    "import preprocessing\n",
    "\n",
    "train_gen, val_gen = preprocessing.preprocess()\n",
    "\n",
    "# Convert classification labels to one-hot encoding\n",
    "# y_class_one_hot = tf.keras.utils.to_categorical(y_class, num_classes=num_classes)\n",
    "\n",
    "# Train the model using the fit method\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "# Save the trained model if needed\n",
    "model.save('multi_task_model.h5')"
   ],
   "metadata": {
    "id": "oU_YBQVkB3qS",
    "ExecuteTime": {
     "end_time": "2023-12-07T15:56:20.435929500Z",
     "start_time": "2023-12-07T15:55:56.713909Z"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 validated image filenames.\n",
      "Found 1 validated image filenames.\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.1683 - binary_classification_output_loss: 0.6932 - regression_output_loss: 0.4751 - binary_classification_output_accuracy: 0.5000 - regression_output_mse: 0.4751 - val_loss: 1278.3817 - val_binary_classification_output_loss: 2.2105 - val_regression_output_loss: 1276.1711 - val_binary_classification_output_accuracy: 0.5000 - val_regression_output_mse: 1276.1711\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1204.8446 - binary_classification_output_loss: 2.1588 - regression_output_loss: 1202.6858 - binary_classification_output_accuracy: 0.5000 - regression_output_mse: 1202.6858 - val_loss: 3.3429 - val_binary_classification_output_loss: 3.0191 - val_regression_output_loss: 0.3239 - val_binary_classification_output_accuracy: 0.5000 - val_regression_output_mse: 0.3239\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.2831 - binary_classification_output_loss: 2.9563 - regression_output_loss: 0.3268 - binary_classification_output_accuracy: 0.5000 - regression_output_mse: 0.3268 - val_loss: 16.8811 - val_binary_classification_output_loss: 2.1675 - val_regression_output_loss: 14.7136 - val_binary_classification_output_accuracy: 0.5000 - val_regression_output_mse: 14.7136\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 16.6189 - binary_classification_output_loss: 2.1536 - regression_output_loss: 14.4654 - binary_classification_output_accuracy: 0.5000 - regression_output_mse: 14.4654 - val_loss: 6.5178 - val_binary_classification_output_loss: 1.3899 - val_regression_output_loss: 5.1279 - val_binary_classification_output_accuracy: 0.5000 - val_regression_output_mse: 5.1279\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.9924 - binary_classification_output_loss: 1.3209 - regression_output_loss: 4.6715 - binary_classification_output_accuracy: 0.5000 - regression_output_mse: 4.6715 - val_loss: 1.1638 - val_binary_classification_output_loss: 0.7339 - val_regression_output_loss: 0.4300 - val_binary_classification_output_accuracy: 0.5000 - val_regression_output_mse: 0.4300\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1665 - binary_classification_output_loss: 0.7296 - regression_output_loss: 0.4369 - binary_classification_output_accuracy: 0.5000 - regression_output_mse: 0.4369 - val_loss: 1.8791 - val_binary_classification_output_loss: 0.8087 - val_regression_output_loss: 1.0704 - val_binary_classification_output_accuracy: 0.5000 - val_regression_output_mse: 1.0704\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.7213 - binary_classification_output_loss: 0.7939 - regression_output_loss: 0.9274 - binary_classification_output_accuracy: 0.5000 - regression_output_mse: 0.9274 - val_loss: 2.2442 - val_binary_classification_output_loss: 0.9436 - val_regression_output_loss: 1.3006 - val_binary_classification_output_accuracy: 0.5000 - val_regression_output_mse: 1.3006\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.8818 - binary_classification_output_loss: 0.8958 - regression_output_loss: 0.9860 - binary_classification_output_accuracy: 0.5000 - regression_output_mse: 0.9860 - val_loss: 1.6077 - val_binary_classification_output_loss: 0.9395 - val_regression_output_loss: 0.6682 - val_binary_classification_output_accuracy: 0.5000 - val_regression_output_mse: 0.6682\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.5007 - binary_classification_output_loss: 0.9113 - regression_output_loss: 0.5894 - binary_classification_output_accuracy: 0.5000 - regression_output_mse: 0.5894 - val_loss: 1.2486 - val_binary_classification_output_loss: 0.9106 - val_regression_output_loss: 0.3379 - val_binary_classification_output_accuracy: 0.5000 - val_regression_output_mse: 0.3379\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1824 - binary_classification_output_loss: 0.8808 - regression_output_loss: 0.3016 - binary_classification_output_accuracy: 0.5000 - regression_output_mse: 0.3016 - val_loss: 1.1001 - val_binary_classification_output_loss: 0.8390 - val_regression_output_loss: 0.2611 - val_binary_classification_output_accuracy: 0.5000 - val_regression_output_mse: 0.2611\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[[[0.03137255, 0.        , 0.        ],\n          [0.03137255, 0.        , 0.        ],\n          [0.03137255, 0.        , 0.        ],\n          ...,\n          [0.4321899 , 0.38905266, 0.31750214],\n          [0.43224734, 0.3891101 , 0.31755322],\n          [0.4323048 , 0.38916755, 0.31760427]],\n \n         [[0.03137255, 0.        , 0.        ],\n          [0.03137255, 0.        , 0.        ],\n          [0.03137255, 0.        , 0.        ],\n          ...,\n          [0.33484775, 0.28559452, 0.21806426],\n          [0.3349403 , 0.28569347, 0.21816002],\n          [0.33503285, 0.28579238, 0.21825576]],\n \n         [[0.03137255, 0.        , 0.        ],\n          [0.03137255, 0.        , 0.        ],\n          [0.03137255, 0.        , 0.        ],\n          ...,\n          [0.27769738, 0.22671698, 0.16005032],\n          [0.27773568, 0.22675528, 0.16008861],\n          [0.27777398, 0.22679357, 0.16012691]],\n \n         ...,\n \n         [[0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ],\n          ...,\n          [0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ]],\n \n         [[0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ],\n          ...,\n          [0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ]],\n \n         [[0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ],\n          ...,\n          [0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ]]],\n \n \n        [[[0.64819145, 0.5169066 , 0.40810782],\n          [0.6826451 , 0.5428383 , 0.42570004],\n          [0.74467534, 0.5893266 , 0.46143144],\n          ...,\n          [0.34204832, 0.2767759 , 0.18000032],\n          [0.34205252, 0.2767793 , 0.18000412],\n          [0.34205675, 0.27678263, 0.18000792]],\n \n         [[0.6469759 , 0.5118727 , 0.40403667],\n          [0.6816097 , 0.53721344, 0.42000437],\n          [0.7457608 , 0.58597505, 0.45747393],\n          ...,\n          [0.32035068, 0.25760555, 0.15956633],\n          [0.32035235, 0.25760725, 0.15956801],\n          [0.320354  , 0.25760892, 0.15956971]],\n \n         [[0.6417617 , 0.50642216, 0.39776292],\n          [0.6781122 , 0.5324787 , 0.41113308],\n          [0.745492  , 0.5842678 , 0.4519155 ],\n          ...,\n          [0.3062349 , 0.24348982, 0.14919588],\n          [0.30623662, 0.24349152, 0.14919674],\n          [0.3062383 , 0.24349318, 0.14919758]],\n \n         ...,\n \n         [[0.8843621 , 0.8686758 , 0.8725974 ],\n          [0.8799118 , 0.8642255 , 0.8681471 ],\n          [0.87079936, 0.8551131 , 0.85903466],\n          ...,\n          [0.97318643, 0.9653433 , 0.98495114],\n          [0.973186  , 0.9653429 , 0.9849507 ],\n          [0.9731856 , 0.96534246, 0.9849503 ]],\n \n         [[0.88897294, 0.87328666, 0.87720823],\n          [0.88404614, 0.86835986, 0.87228143],\n          [0.87759477, 0.8619085 , 0.86583006],\n          ...,\n          [0.976226  , 0.96838284, 0.9879907 ],\n          [0.9762264 , 0.96838325, 0.9879911 ],\n          [0.9762268 , 0.96838367, 0.9879915 ]],\n \n         [[0.89902705, 0.8833407 , 0.8872623 ],\n          [0.8946443 , 0.87895805, 0.8828796 ],\n          [0.8908344 , 0.8751481 , 0.8790697 ],\n          ...,\n          [0.972697  , 0.9648539 , 0.9844617 ],\n          [0.97269744, 0.9648543 , 0.98446214],\n          [0.97269785, 0.9648547 , 0.98446256]]],\n \n \n        [[[0.55612177, 0.4001368 , 0.30355108],\n          [0.6207345 , 0.44596866, 0.33786947],\n          [0.6767484 , 0.4893228 , 0.367008  ],\n          ...,\n          [0.62424964, 0.5665065 , 0.57791114],\n          [0.6311807 , 0.58383393, 0.59177303],\n          [0.68865454, 0.6415957 , 0.64943886]],\n \n         [[0.56196386, 0.40651467, 0.30742097],\n          [0.6276197 , 0.45228285, 0.34178072],\n          [0.6836336 , 0.49467772, 0.37119856],\n          ...,\n          [0.6321228 , 0.5732091 , 0.58621687],\n          [0.63194704, 0.5829314 , 0.59145576],\n          [0.68156886, 0.6342747 , 0.6421963 ]],\n \n         [[0.58388644, 0.43026295, 0.32332337],\n          [0.65259296, 0.475542  , 0.3576048 ],\n          [0.70819277, 0.51445866, 0.3873912 ],\n          ...,\n          [0.6832411 , 0.61724496, 0.6397686 ],\n          [0.6395365 , 0.5796383 , 0.593015  ],\n          [0.6399396 , 0.5899459 , 0.59891534]],\n \n         ...,\n \n         [[0.382712  , 0.24783987, 0.20063718],\n          [0.4064796 , 0.2592159 , 0.20810473],\n          [0.41683003, 0.26398477, 0.20730591],\n          ...,\n          [0.87135565, 0.8406216 , 0.82939637],\n          [0.901744  , 0.8846196 , 0.8677032 ],\n          [0.9129193 , 0.9027247 , 0.8839003 ]],\n \n         [[0.40940106, 0.25866982, 0.20847945],\n          [0.43379232, 0.2794818 , 0.22235447],\n          [0.44899324, 0.28560466, 0.23023935],\n          ...,\n          [0.8930982 , 0.868401  , 0.8588152 ],\n          [0.8981275 , 0.88606274, 0.8729578 ],\n          [0.9045821 , 0.9020531 , 0.8855182 ]],\n \n         [[0.43637985, 0.26272514, 0.21977198],\n          [0.46705455, 0.28667563, 0.23711948],\n          [0.47798118, 0.29068926, 0.24271195],\n          ...,\n          [0.87308633, 0.8618708 , 0.8560459 ],\n          [0.8979002 , 0.89358777, 0.8854912 ],\n          [0.91191167, 0.9080698 , 0.89979714]]],\n \n \n        ...,\n \n \n        [[[0.5764706 , 0.46274513, 0.30588236],\n          [0.5815842 , 0.46785873, 0.31099597],\n          [0.59527606, 0.48155057, 0.3246878 ],\n          ...,\n          [0.8745099 , 0.78823537, 0.6039216 ],\n          [0.8604333 , 0.7741588 , 0.58984506],\n          [0.8497488 , 0.7634743 , 0.5740073 ]],\n \n         [[0.5764706 , 0.46274513, 0.30588236],\n          [0.581643  , 0.4679175 , 0.31105474],\n          [0.5953201 , 0.48159465, 0.3247319 ],\n          ...,\n          [0.8745099 , 0.78823537, 0.6039216 ],\n          [0.86035985, 0.77408534, 0.5897716 ],\n          [0.8497194 , 0.7634449 , 0.5739485 ]],\n \n         [[0.5764706 , 0.46274513, 0.30588236],\n          [0.58170176, 0.46797627, 0.3111135 ],\n          [0.59536415, 0.4816387 , 0.32477596],\n          ...,\n          [0.8745099 , 0.78823537, 0.6039216 ],\n          [0.8602864 , 0.77401185, 0.58969814],\n          [0.84969   , 0.7634155 , 0.57388973]],\n \n         ...,\n \n         [[0.6627451 , 0.74509805, 0.85098046],\n          [0.65340084, 0.73886853, 0.83540654],\n          [0.64810437, 0.7343789 , 0.8284965 ],\n          ...,\n          [0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ]],\n \n         [[0.6627451 , 0.74509805, 0.85098046],\n          [0.65335673, 0.73883915, 0.8353331 ],\n          [0.64808965, 0.73436415, 0.8284818 ],\n          ...,\n          [0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ]],\n \n         [[0.6627451 , 0.74509805, 0.85098046],\n          [0.6533127 , 0.73880976, 0.8352596 ],\n          [0.648075  , 0.7343495 , 0.82846713],\n          ...,\n          [0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ]]],\n \n \n        [[[0.80782914, 0.5333193 , 0.3293977 ],\n          [0.8078432 , 0.53333336, 0.32941177],\n          [0.8144542 , 0.5366389 , 0.32610628],\n          ...,\n          [0.87766826, 0.76786435, 0.68551135],\n          [0.9094797 , 0.7996757 , 0.71732277],\n          [0.95294124, 0.8431373 , 0.7607844 ]],\n \n         [[0.8078432 , 0.53333336, 0.32941177],\n          [0.8078432 , 0.53333336, 0.32941177],\n          [0.81447244, 0.536648  , 0.32609716],\n          ...,\n          [0.8777411 , 0.7679371 , 0.6855842 ],\n          [0.909598  , 0.7997941 , 0.71744114],\n          [0.95294124, 0.8431373 , 0.7607844 ]],\n \n         [[0.8078432 , 0.53333336, 0.32941177],\n          [0.8078432 , 0.53333336, 0.32941177],\n          [0.8144906 , 0.5366571 , 0.32608807],\n          ...,\n          [0.8778139 , 0.76800996, 0.685657  ],\n          [0.90971637, 0.79991245, 0.7175595 ],\n          [0.95294124, 0.8431373 , 0.7607844 ]],\n \n         ...,\n \n         [[0.8980393 , 0.60784316, 0.4156863 ],\n          [0.8955539 , 0.60535777, 0.41320094],\n          [0.8831436 , 0.5929475 , 0.4007906 ],\n          ...,\n          [0.8276994 , 0.6669151 , 0.55711114],\n          [0.84902424, 0.6899562 , 0.5835848 ],\n          [0.86666673, 0.70980394, 0.60784316]],\n \n         [[0.8980393 , 0.60784316, 0.4156863 ],\n          [0.8955266 , 0.6053305 , 0.41317362],\n          [0.88308895, 0.5928928 , 0.40073597],\n          ...,\n          [0.82773584, 0.66695154, 0.5571476 ],\n          [0.8490971 , 0.69003814, 0.5836849 ],\n          [0.86666673, 0.70980394, 0.60784316]],\n \n         [[0.8980393 , 0.60784316, 0.4156863 ],\n          [0.8954993 , 0.6053032 , 0.41314632],\n          [0.8830343 , 0.5928382 , 0.40068138],\n          ...,\n          [0.82777226, 0.6669879 , 0.557184  ],\n          [0.8491699 , 0.69012004, 0.5837851 ],\n          [0.86666673, 0.70980394, 0.60784316]]],\n \n \n        [[[0.4728065 , 0.4335908 , 0.39437512],\n          [0.37693232, 0.33341062, 0.29563025],\n          [0.27642182, 0.2237723 , 0.18847819],\n          ...,\n          [0.59607846, 0.45098042, 0.4156863 ],\n          [0.59607846, 0.45098042, 0.4156863 ],\n          [0.59607846, 0.45098042, 0.4156863 ]],\n \n         [[0.46940583, 0.43019015, 0.39097446],\n          [0.38145512, 0.33785275, 0.30009925],\n          [0.28005493, 0.22737852, 0.1920844 ],\n          ...,\n          [0.59607846, 0.45098042, 0.4156863 ],\n          [0.59607846, 0.45098042, 0.4156863 ],\n          [0.59607846, 0.45098042, 0.4156863 ]],\n \n         [[0.46823588, 0.42902017, 0.38980448],\n          [0.39573777, 0.3520547 , 0.3143281 ],\n          [0.2920524 , 0.23934911, 0.204055  ],\n          ...,\n          [0.5879276 , 0.4428295 , 0.40753537],\n          [0.5879533 , 0.44285527, 0.40756115],\n          [0.5879791 , 0.44288102, 0.4075869 ]],\n \n         ...,\n \n         [[0.77647066, 0.5921569 , 0.5542261 ],\n          [0.7738419 , 0.5895282 , 0.55815566],\n          [0.76026595, 0.5759522 , 0.54679966],\n          ...,\n          [0.90196085, 0.7686275 , 0.72156864],\n          [0.90196085, 0.7686275 , 0.72156864],\n          [0.90196085, 0.7686275 , 0.72156864]],\n \n         [[0.77647066, 0.5921569 , 0.5542799 ],\n          [0.7737613 , 0.58944756, 0.558075  ],\n          [0.7601583 , 0.5758446 , 0.54674584],\n          ...,\n          [0.90196085, 0.7686275 , 0.72156864],\n          [0.90196085, 0.7686275 , 0.72156864],\n          [0.90196085, 0.7686275 , 0.72156864]],\n \n         [[0.77647066, 0.5921569 , 0.5543337 ],\n          [0.77368057, 0.5893668 , 0.55799425],\n          [0.7600507 , 0.575737  , 0.5466921 ],\n          ...,\n          [0.90196085, 0.7686275 , 0.72156864],\n          [0.90196085, 0.7686275 , 0.72156864],\n          [0.90196085, 0.7686275 , 0.72156864]]]], dtype=float32),\n array([[1, 0],\n        [1, 0],\n        [1, 0],\n        [1, 0],\n        [1, 0],\n        [1, 0],\n        [1, 0],\n        [1, 0]], dtype=int64))"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen.next()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T15:53:19.539034600Z",
     "start_time": "2023-12-07T15:53:19.350940800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check for overfitting"
   ],
   "metadata": {
    "id": "y7sH8aihCoFB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot Classification Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['classification_output_loss'], label='classification_loss')\n",
    "plt.plot(history.history['val_classification_output_loss'], label='val_classification_loss')\n",
    "plt.title('Classification Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Regression Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['regression_output_loss'], label='regression_loss')\n",
    "plt.plot(history.history['val_regression_output_loss'], label='val_regression_loss')\n",
    "plt.title('Regression Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "iaJdYnJCCq3g",
    "ExecuteTime": {
     "end_time": "2023-12-07T15:57:03.295736700Z",
     "start_time": "2023-12-07T15:56:59.561915600Z"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'classification_output_loss'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [6], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# Plot Classification Loss\u001B[39;00m\n\u001B[0;32m      7\u001B[0m plt\u001B[38;5;241m.\u001B[39msubplot(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m----> 8\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(\u001B[43mhistory\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhistory\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mclassification_output_loss\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m, label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclassification_loss\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      9\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(history\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_classification_output_loss\u001B[39m\u001B[38;5;124m'\u001B[39m], label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_classification_loss\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     10\u001B[0m plt\u001B[38;5;241m.\u001B[39mtitle(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mClassification Loss\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'classification_output_loss'"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1200x600 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  }
 ]
}
