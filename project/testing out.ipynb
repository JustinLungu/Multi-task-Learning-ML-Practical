{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-09T15:39:56.982975600Z",
     "start_time": "2023-12-09T15:39:56.540966200Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Lambda, Layer\n",
    "from keras.initializers import Constant\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import preprocessing\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Custom loss layer\n",
    "class CustomMultiLossLayer(Layer):\n",
    "    def __init__(self, nb_outputs=2, **kwargs):\n",
    "        self.nb_outputs = nb_outputs\n",
    "        self.is_placeholder = True\n",
    "        super(CustomMultiLossLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape=None):\n",
    "        # initialise log_vars\n",
    "        self.log_vars = []\n",
    "        for i in range(self.nb_outputs):\n",
    "            self.log_vars += [self.add_weight(name='log_var' + str(i), shape=(1,),\n",
    "                                              initializer=Constant(0.), trainable=True)]\n",
    "        super(CustomMultiLossLayer, self).build(input_shape)\n",
    "\n",
    "    def multi_loss(self, ys_true, ys_pred):\n",
    "        assert len(ys_true) == self.nb_outputs and len(ys_pred) == self.nb_outputs\n",
    "        loss = 0\n",
    "        for y_true, y_pred, log_var in zip(ys_true, ys_pred, self.log_vars):\n",
    "            precision = K.exp(-log_var[0])\n",
    "            loss += K.sum(precision * (y_true - y_pred)**2. + log_var[0], -1)\n",
    "        return K.mean(loss)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        ys_true = inputs[:self.nb_outputs]\n",
    "        ys_pred = inputs[self.nb_outputs:]\n",
    "        loss = self.multi_loss(ys_true, ys_pred)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # We won't actually use the output.\n",
    "        return K.concatenate(inputs, -1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T15:22:36.488516Z",
     "start_time": "2023-12-09T15:22:36.400517600Z"
    }
   },
   "id": "8b18ff5696deccdd"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "N = 100\n",
    "nb_epoch = 3\n",
    "batch_size = 20\n",
    "Q = 1\n",
    "D1 = 1  # first output\n",
    "D2 = 1  # second output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T15:29:10.035050700Z",
     "start_time": "2023-12-09T15:29:09.891639Z"
    }
   },
   "id": "2ecafc46cd327f04"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_26\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)          [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 126, 126, 64  1792        ['input_10[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 124, 124, 64  36928       ['conv2d_17[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 62, 62, 64)  0           ['conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_8 (Flatten)            (None, 246016)       0           ['max_pooling2d_8[0][0]']        \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 128)          31490176    ['flatten_8[0][0]']              \n",
      "                                                                                                  \n",
      " regression (Dense)             (None, 1)            129         ['dense_26[0][0]']               \n",
      "                                                                                                  \n",
      " classification (Dense)         (None, 1)            129         ['dense_26[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,529,154\n",
      "Trainable params: 31,529,154\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_27\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inp (InputLayer)               [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " regression_true (InputLayer)   [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " classification_true (InputLaye  [(None, 1)]         0           []                               \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " model_26 (Functional)          [(None, 1),          31529154    ['inp[0][0]']                    \n",
      "                                 (None, 1)]                                                       \n",
      "                                                                                                  \n",
      " custom_multi_loss_layer_11 (Cu  (None, 4)           2           ['regression_true[0][0]',        \n",
      " stomMultiLossLayer)                                              'classification_true[0][0]',    \n",
      "                                                                  'model_26[0][0]',               \n",
      "                                                                  'model_26[0][1]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,529,156\n",
      "Trainable params: 31,529,156\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (128,128,3)\n",
    "def get_prediction_model():\n",
    "    inp = Input(shape=input_shape)\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu')(inp)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu')(conv1)\n",
    "    max_pool = MaxPooling2D((2, 2))(conv2)\n",
    "    flatten = Flatten()(max_pool)\n",
    "    dense_shared = Dense(128, activation='relu')(flatten)\n",
    "    classification_output = layers.Dense(1, activation='sigmoid', name='classification')(dense_shared)\n",
    "    regression_output = layers.Dense(1, activation='linear', name='regression')(dense_shared)\n",
    "    return Model(inp, [regression_output, classification_output])\n",
    "\n",
    "def get_trainable_model(prediction_model):\n",
    "    inp = Input(shape=(128,128,3), name='inp')\n",
    "    regression_pred, classification_pred = prediction_model(inp)\n",
    "    regression_true = Input(shape=(D1,), name='regression_true')\n",
    "    classification_true = Input(shape=(D2,), name='classification_true')\n",
    "    out = CustomMultiLossLayer(nb_outputs=2)([regression_true, classification_true, regression_pred, classification_pred])\n",
    "    return Model([inp, regression_true, classification_true], out)\n",
    "\n",
    "prediction_model = get_prediction_model()\n",
    "trainable_model = get_trainable_model(prediction_model)\n",
    "trainable_model.compile(optimizer='adam', loss=None)\n",
    "assert len(trainable_model.layers[-1].trainable_weights) == 2  # two log_vars, one for each output\n",
    "assert len(trainable_model.losses) == 1\n",
    "prediction_model.summary()\n",
    "trainable_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:06:28.077767400Z",
     "start_time": "2023-12-09T16:06:24.287363700Z"
    }
   },
   "id": "9898dd82fa74d6ac"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 validated image filenames.\n",
      "Found 1 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_gen, val_gen = preprocessing.preprocess()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T15:23:48.466075200Z",
     "start_time": "2023-12-09T15:23:47.452851800Z"
    }
   },
   "id": "539a743354fafe92"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[[[0.69945747, 0.62886924, 0.62886924],\n          [0.6994332 , 0.628845  , 0.628845  ],\n          [0.6994089 , 0.62882066, 0.62882066],\n          ...,\n          [0.45813605, 0.37970465, 0.3365674 ],\n          [0.4581846 , 0.37975323, 0.33661598],\n          [0.45823315, 0.37980178, 0.33666453]],\n \n         [[0.69411767, 0.62352943, 0.62352943],\n          [0.69411767, 0.62352943, 0.62352943],\n          [0.69411767, 0.62352943, 0.62352943],\n          ...,\n          [0.46478993, 0.38635856, 0.34322128],\n          [0.46480206, 0.3863707 , 0.34323344],\n          [0.46481422, 0.38638285, 0.3432456 ]],\n \n         [[0.69411767, 0.62352943, 0.62352943],\n          [0.69411767, 0.62352943, 0.62352943],\n          [0.69411767, 0.62352943, 0.62352943],\n          ...,\n          [0.4719479 , 0.39351654, 0.3503793 ],\n          [0.47199646, 0.3935651 , 0.35042784],\n          [0.47204506, 0.3936137 , 0.3504764 ]],\n \n         ...,\n \n         [[0.7058824 , 0.63529414, 0.63529414],\n          [0.7058824 , 0.63529414, 0.63529414],\n          [0.7058824 , 0.63529414, 0.63529414],\n          ...,\n          [0.7490196 , 0.77647066, 0.81568635],\n          [0.7490196 , 0.77647066, 0.81568635],\n          [0.7490196 , 0.77647066, 0.81568635]],\n \n         [[0.7057211 , 0.63513285, 0.63513285],\n          [0.7057089 , 0.6351207 , 0.6351207 ],\n          [0.70569676, 0.63510853, 0.63510853],\n          ...,\n          [0.7506986 , 0.7781496 , 0.8173653 ],\n          [0.7507107 , 0.7781617 , 0.8173774 ],\n          [0.7507229 , 0.77817386, 0.81738955]],\n \n         [[0.70252395, 0.6319357 , 0.6319357 ],\n          [0.7025119 , 0.6319236 , 0.6319236 ],\n          [0.70249975, 0.6319115 , 0.6319115 ],\n          ...,\n          [0.75485015, 0.7823011 , 0.8215168 ],\n          [0.7548744 , 0.7823254 , 0.8215411 ],\n          [0.75489867, 0.78234965, 0.82156533]]],\n \n \n        [[[0.6023674 , 0.37491646, 0.18668114],\n          [0.61885583, 0.39105627, 0.20247237],\n          [0.65788937, 0.42952707, 0.24038047],\n          ...,\n          [0.9195708 , 0.8097669 , 0.72741395],\n          [0.91959757, 0.8097936 , 0.72744066],\n          [0.91962427, 0.80982035, 0.7274674 ]],\n \n         [[0.6286303 , 0.39917427, 0.20893402],\n          [0.6467706 , 0.41510957, 0.22266419],\n          [0.68640846, 0.45111433, 0.2550359 ],\n          ...,\n          [0.8986004 , 0.7887964 , 0.7064435 ],\n          [0.8986449 , 0.788841  , 0.7064881 ],\n          [0.8986895 , 0.7888856 , 0.70653266]],\n \n         [[0.657965  , 0.42267084, 0.2265924 ],\n          [0.67417586, 0.4377124 , 0.24104926],\n          [0.71017116, 0.4718497 , 0.27425763],\n          ...,\n          [0.87409306, 0.76428914, 0.6819362 ],\n          [0.874102  , 0.7642981 , 0.68194515],\n          [0.87411094, 0.76430696, 0.681954  ]],\n \n         ...,\n \n         [[0.8745099 , 0.58431375, 0.40000004],\n          [0.8745099 , 0.58431375, 0.40000004],\n          [0.87863916, 0.5884431 , 0.40412933],\n          ...,\n          [0.86666673, 0.70980394, 0.60784316],\n          [0.86666673, 0.70980394, 0.60784316],\n          [0.86666673, 0.70980394, 0.60784316]],\n \n         [[0.8745099 , 0.58431375, 0.40000004],\n          [0.8745099 , 0.58431375, 0.40000004],\n          [0.87865645, 0.5884604 , 0.40414664],\n          ...,\n          [0.86666673, 0.70980394, 0.60784316],\n          [0.86666673, 0.70980394, 0.60784316],\n          [0.86666673, 0.70980394, 0.60784316]],\n \n         [[0.8745099 , 0.58431375, 0.40000004],\n          [0.8745099 , 0.58431375, 0.40000004],\n          [0.8786738 , 0.5884777 , 0.40416393],\n          ...,\n          [0.86666673, 0.70980394, 0.60784316],\n          [0.86666673, 0.70980394, 0.60784316],\n          [0.86666673, 0.70980394, 0.60784316]]],\n \n \n        [[[0.59522074, 0.4501227 , 0.4148286 ],\n          [0.59521914, 0.45012107, 0.41482696],\n          [0.5952175 , 0.45011947, 0.41482535],\n          ...,\n          [0.35241356, 0.25098997, 0.209339  ],\n          [0.31392056, 0.22309862, 0.18223508],\n          [0.2777424 , 0.19146787, 0.14833061]],\n \n         [[0.5873193 , 0.44222125, 0.40692714],\n          [0.58731765, 0.44221961, 0.4069255 ],\n          [0.58731604, 0.44221798, 0.40692386],\n          ...,\n          [0.35077134, 0.24934168, 0.20768866],\n          [0.30559492, 0.21476893, 0.1739074 ],\n          [0.2664638 , 0.1801893 , 0.13705204]],\n \n         [[0.5789307 , 0.43383262, 0.3985385 ],\n          [0.57892823, 0.4338302 , 0.3985361 ],\n          [0.5789258 , 0.43382776, 0.3985336 ],\n          ...,\n          [0.35778907, 0.25635335, 0.21469831],\n          [0.3059342 , 0.21510418, 0.17424467],\n          [0.2606651 , 0.1743906 , 0.13125335]],\n \n         ...,\n \n         [[0.8981915 , 0.7648582 , 0.7177993 ],\n          [0.8981923 , 0.76485896, 0.7178001 ],\n          [0.8981931 , 0.7648598 , 0.717801  ],\n          ...,\n          [0.75249475, 0.5787124 , 0.54711837],\n          [0.74380666, 0.56454617, 0.54101676],\n          [0.74642146, 0.56210774, 0.53857833]],\n \n         [[0.90196085, 0.7686275 , 0.72156864],\n          [0.90196085, 0.7686275 , 0.72156864],\n          [0.90196085, 0.7686275 , 0.72156864],\n          ...,\n          [0.74286294, 0.56908256, 0.53748244],\n          [0.725233  , 0.5459765 , 0.5224471 ],\n          [0.7207562 , 0.53644246, 0.51291305]],\n \n         [[0.90196085, 0.7686275 , 0.72156864],\n          [0.90196085, 0.7686275 , 0.72156864],\n          [0.90196085, 0.7686275 , 0.72156864],\n          ...,\n          [0.7428731 , 0.5690947 , 0.5374885 ],\n          [0.72523904, 0.5459866 , 0.5224572 ],\n          [0.7207522 , 0.53643847, 0.51290905]]],\n \n \n        ...,\n \n \n        [[[0.46558237, 0.42244512, 0.34718433],\n          [0.4654723 , 0.42233506, 0.3470865 ],\n          [0.46536228, 0.42222503, 0.34698868],\n          ...,\n          [0.03137255, 0.        , 0.        ],\n          [0.03137255, 0.        , 0.        ],\n          [0.03137255, 0.        , 0.        ]],\n \n         [[0.39215   , 0.34684867, 0.27734247],\n          [0.39197272, 0.34665912, 0.27715907],\n          [0.39179543, 0.3464696 , 0.27697563],\n          ...,\n          [0.03137255, 0.        , 0.        ],\n          [0.03137255, 0.        , 0.        ],\n          [0.03137255, 0.        , 0.        ]],\n \n         [[0.30285832, 0.25187793, 0.18521124],\n          [0.30278492, 0.25180453, 0.18513788],\n          [0.30271158, 0.25173116, 0.18506451],\n          ...,\n          [0.03137255, 0.        , 0.        ],\n          [0.03137255, 0.        , 0.        ],\n          [0.03137255, 0.        , 0.        ]],\n \n         ...,\n \n         [[0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ],\n          ...,\n          [0.00173272, 0.        , 0.        ],\n          [0.0017266 , 0.        , 0.        ],\n          [0.00172049, 0.        , 0.        ]],\n \n         [[0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ],\n          ...,\n          [0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ]],\n \n         [[0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ],\n          ...,\n          [0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ],\n          [0.        , 0.        , 0.        ]]],\n \n \n        [[[0.8357947 , 0.60442215, 0.44755936],\n          [0.8389529 , 0.60758036, 0.4507176 ],\n          [0.8421111 , 0.6107386 , 0.45387584],\n          ...,\n          [0.32774454, 0.33246452, 0.2586827 ],\n          [0.323894  , 0.32781556, 0.25722733],\n          [0.30966458, 0.31358615, 0.24619089]],\n \n         [[0.83576745, 0.60439485, 0.44753215],\n          [0.8389257 , 0.6075531 , 0.4506904 ],\n          [0.84208393, 0.61071134, 0.4538486 ],\n          ...,\n          [0.3275539 , 0.33230108, 0.2584103 ],\n          [0.32400295, 0.32792452, 0.2573363 ],\n          [0.30980077, 0.31372234, 0.24627262]],\n \n         [[0.8357402 , 0.6043676 , 0.44750488],\n          [0.8388985 , 0.6075259 , 0.45066312],\n          [0.8420567 , 0.6106841 , 0.45382136],\n          ...,\n          [0.32736322, 0.33213767, 0.25813788],\n          [0.32411194, 0.3280335 , 0.25744525],\n          [0.30993697, 0.31385854, 0.24635433]],\n \n         ...,\n \n         [[0.8716367 , 0.83841354, 0.8573311 ],\n          [0.8724209 , 0.8397987 , 0.8585159 ],\n          [0.8697741 , 0.84497803, 0.86108655],\n          ...,\n          [0.8714333 , 0.85574704, 0.8596686 ],\n          [0.8705883 , 0.854902  , 0.8588236 ],\n          [0.8681964 , 0.85251015, 0.8564317 ]],\n \n         [[0.8660664 , 0.8307723 , 0.8503801 ],\n          [0.86333096, 0.82787997, 0.84809804],\n          [0.8630772 , 0.82540685, 0.8541608 ],\n          ...,\n          [0.87414676, 0.8584605 , 0.86238205],\n          [0.87260425, 0.856918  , 0.86083955],\n          [0.8682088 , 0.85252255, 0.8564441 ]],\n \n         [[0.85774267, 0.81873107, 0.8500356 ],\n          [0.854193  , 0.8157964 , 0.84689593],\n          [0.8478385 , 0.81873333, 0.8467358 ],\n          ...,\n          [0.88084865, 0.86390597, 0.87159675],\n          [0.8779101 , 0.8609579 , 0.8686772 ],\n          [0.87370807, 0.8567464 , 0.8644942 ]]],\n \n \n        [[[0.6941444 , 0.6470856 , 0.65492874],\n          [0.63945305, 0.59239423, 0.60023737],\n          [0.62588894, 0.5706047 , 0.5811896 ],\n          ...,\n          [0.8525303 , 0.6407656 , 0.49484572],\n          [0.8526477 , 0.640883  , 0.49186337],\n          [0.85201347, 0.6412116 , 0.4902663 ]],\n \n         [[0.6941115 , 0.6470527 , 0.65489584],\n          [0.63942015, 0.59236133, 0.60020447],\n          [0.62588507, 0.57059497, 0.5811819 ],\n          ...,\n          [0.8525284 , 0.6407637 , 0.49483994],\n          [0.8526496 , 0.64088494, 0.4918653 ],\n          [0.8520077 , 0.64120775, 0.49025857]],\n \n         [[0.6940786 , 0.6470198 , 0.65486294],\n          [0.63938725, 0.59232837, 0.6001715 ],\n          [0.6258812 , 0.5705853 , 0.58117414],\n          ...,\n          [0.8525264 , 0.64076173, 0.49483413],\n          [0.8526516 , 0.6408869 , 0.49186724],\n          [0.8520019 , 0.6412039 , 0.49025083]],\n \n         ...,\n \n         [[0.9111549 , 0.9033118 , 0.90723336],\n          [0.9039977 , 0.8961546 , 0.90007615],\n          [0.8837348 , 0.8758917 , 0.87981325],\n          ...,\n          [0.60618806, 0.36043724, 0.28592482],\n          [0.6077054 , 0.3644648 , 0.29387656],\n          [0.6086937 , 0.36827335, 0.30129907]],\n \n         [[0.90933114, 0.901488  , 0.9054096 ],\n          [0.906114  , 0.89827085, 0.9021924 ],\n          [0.88796896, 0.8801258 , 0.8840474 ],\n          ...,\n          [0.63529414, 0.38954145, 0.31503484],\n          [0.63529414, 0.3920574 , 0.32146913],\n          [0.63167435, 0.39125207, 0.3242836 ]],\n \n         [[0.9093292 , 0.90148604, 0.9054076 ],\n          [0.9061121 , 0.89826894, 0.9021905 ],\n          [0.88795733, 0.8801142 , 0.88403577],\n          ...,\n          [0.63529414, 0.38953948, 0.3150387 ],\n          [0.63529414, 0.39206123, 0.321473  ],\n          [0.63166857, 0.39124432, 0.3242817 ]]]], dtype=float32),\n array([[1., 0.],\n        [1., 0.],\n        [1., 0.],\n        [1., 0.],\n        [1., 0.],\n        [1., 0.],\n        [1., 0.],\n        [1., 0.]], dtype=float32))"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen.next()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:04:11.726204300Z",
     "start_time": "2023-12-09T16:04:10.875463200Z"
    }
   },
   "id": "4f44a22262bc6268"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\sophi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\sophi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\sophi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\sophi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\sophi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\sophi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\input_spec.py\", line 219, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model_27\" expects 3 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, None, None, None) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [42], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m hist \u001B[38;5;241m=\u001B[39m \u001B[43mtrainable_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_gen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnb_epoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filer5l12p_u.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    File \"C:\\Users\\sophi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\sophi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\sophi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\sophi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\sophi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\sophi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\input_spec.py\", line 219, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model_27\" expects 3 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, None, None, None) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "hist = trainable_model.fit(train_gen, epochs=nb_epoch, batch_size=batch_size, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:06:33.429202100Z",
     "start_time": "2023-12-09T16:06:32.513082600Z"
    }
   },
   "id": "61123a919b08fd4d"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c5247501887cb53b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
